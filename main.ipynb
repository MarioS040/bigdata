{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
      "  159  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
      "  252 237   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
      "  233 252  57   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
      "   84 252 253 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
      "   96 189 253 167   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "   47  79 255 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
      "    0   0 253 243  50   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
      "    0   0 253 252 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
      "    0   0 255 253 196   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
      "    0   0 253 252 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
      "    7 135 253 186  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
      "  131 252 225  71   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      "  252 173   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
      "   56   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.08216044 0.2286589  0.3728098\n",
      "  0.30506548 0.08583808 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08087653 0.38341541 0.36240278 0.37133624\n",
      "  0.48350001 0.4068725  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08861609 0.3824786  0.40758025 0.36240278 0.35218\n",
      "  0.44704564 0.43262392 0.06832372 0.00859123 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01621743\n",
      "  0.095788   0.36759266 0.42460179 0.40758025 0.36240278 0.29765841\n",
      "  0.16116667 0.43262392 0.30326141 0.17468832 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26434406\n",
      "  0.4023096  0.41354174 0.42460179 0.40758025 0.36240278 0.37133624\n",
      "  0.18419048 0.32446794 0.30326141 0.23912253 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08411834 0.38597476\n",
      "  0.40390606 0.41518278 0.32013627 0.18365276 0.36384089 0.33597088\n",
      "  0.09017659 0.13562417 0.30565873 0.2405544  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07427511 0.39255225 0.40867916\n",
      "  0.4023096  0.29374592 0.02021913 0.12082418 0.17401086 0.03094469\n",
      "  0.         0.         0.30326141 0.34794476 0.12263192 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04890249 0.2553207  0.41729294 0.37786605\n",
      "  0.33206506 0.13784725 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.40468535 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00966301 0.22906954 0.38994434 0.39585101 0.11514373\n",
      "  0.03033287 0.04594908 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07868449 0.32430069 0.38994434 0.10391089 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27332506 0.3255876  0.29400565 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30565873 0.36226348 0.48071715 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.33960736 0.33958568 0.32430069 0.17330859 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.3629905  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.29598873 0.03868495 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01343056 0.23176282 0.30326141 0.26632809 0.02943166 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.28698037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.0103149\n",
      "  0.25134326 0.43262392 0.26969888 0.10166287 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.18660159 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0690291  0.24313682\n",
      "  0.48350001 0.29699976 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.38429254 0.34924869 0.28955419 0.         0.         0.\n",
      "  0.         0.         0.         0.18365276 0.34226929 0.3728098\n",
      "  0.31082143 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32043997 0.22592013 0.0791702  0.04703054\n",
      "  0.13569967 0.29210488 0.37910874 0.40758025 0.3206977  0.24608394\n",
      "  0.10744445 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32430069 0.38994434 0.37770784 0.34867468\n",
      "  0.4023096  0.41354174 0.42460179 0.31575387 0.18695382 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.1251185  0.27470549 0.32430069 0.38994434 0.41729294 0.40867916\n",
      "  0.4023096  0.38236201 0.24431452 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03451074 0.16472416 0.38994434 0.41729294 0.40867916\n",
      "  0.2251018  0.06071843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1749 - accuracy: 0.9468\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0623 - accuracy: 0.9805\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0410 - accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0166 - accuracy: 0.9948\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0109 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0103 - accuracy: 0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: handwritten.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: handwritten.model\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pickletools import optimize\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax')) #alle zusammen = 1 jedes neuron hat eine Zahl zwischen 0 und 1. Probality of each digit\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "model.fit(x_train, y_train, epochs= 10)\n",
    "model.save('handwritten.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('handwritten.model')\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicthandwritten(path): \n",
    " img = cv2.imread(path)[:,:,0]\n",
    " img = np.invert(np.array([img]))\n",
    " prediction = model.predict(img)\n",
    " print(prediction)\n",
    "    \n",
    " plt.imshow(img[0])\n",
    " plt.show()\n",
    " print(np.argmax(prediction))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "predicthandwritten(\"7.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4026d7a36d874e1f6c487603191095e1ef70b08516b0a096b0ced5fbd321bb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
